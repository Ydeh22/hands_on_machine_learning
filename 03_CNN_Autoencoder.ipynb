{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands on Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://atenea.upc.edu/course/view.php?id=71605\" target=\"_blank\">\n",
    "      <img src=\"https://github.com/dmaluenda/deeplearning_course/raw/master/resources/upc_logo_49px.png\" width=\"130\"/>\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "  </td>\n",
    "  <td>   <!-- gColab -->\n",
    "    <a href=\"https://colab.research.google.com/github/dmaluenda/deeplearning_course/blob/master/03_CNN_Autoencoder.ipynb\" target=\"_blank\">\n",
    "      <img src=\"https://raw.githubusercontent.com/dmaluenda/deeplearning_course/master/resources/colab_logo_32px.png\" />\n",
    "      Run in Google Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>   <!-- github -->\n",
    "    <a href=\"https://github.com/dmaluenda/deeplearning_course/blob/master/03_CNN_Autoencoder.ipynb\" target=\"_blank\">\n",
    "      <img src=\"https://raw.githubusercontent.com/dmaluenda/deeplearning_course/master/resources/github_logo_32px.png\" />\n",
    "      View source on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>   <!-- download -->\n",
    "    <a href=\"https://raw.githubusercontent.com/dmaluenda/deeplearning_course/master/03_CNN_Autoencoder.ipynb\"  target=\"_blank\"\n",
    "          download=\"03_CNN_Autoencoder\">\n",
    "      <img src=\"https://raw.githubusercontent.com/dmaluenda/deeplearning_course/master/resources/download_logo_32px.png\" />\n",
    "      Download notebook\n",
    "      </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\text{III}$. Convolutional Neural Networks and Autoencoders (using Keras)\n",
    "\n",
    "Hands on \"Machine Learning on Classical and Quantum data\" course of\n",
    "[Master in Photonics - PHOTONICS BCN](https://photonics.masters.upc.edu/en/general-information)\n",
    "[[UPC](https://photonics.masters.upc.edu/en) +\n",
    "[UB](https://www.ub.edu/web/ub/en/estudis/oferta_formativa/master_universitari/fitxa/P/M0D0H/index.html?) +\n",
    "[UAB](https://www.uab.cat/en/uab-official-masters-degrees-study-guides/) +\n",
    "[ICFO](https://www.icfo.eu/lang/studies/master-studies)].\n",
    "\n",
    "Tutorial 3\n",
    "\n",
    "This notebook shows how to:\n",
    "- implement a neural network using the Keras module\n",
    "- recognize images with dense nets (supervised learning)\n",
    "- recognize images with convolutional nets (supervised learning)\n",
    "- implement image denoising using pseudo-encoders (almost unsupervised learning)\n",
    "- generate images (U-net, GAN, cGAN and VAE)\n",
    "- implement anomaly detection with an Autoencoder (1D)\n",
    "\n",
    "**References**:\n",
    "\n",
    "[1] [Machine Learning for Physicists](https://machine-learning-for-physicists.org/) by Florian Marquardt.<br>\n",
    "[2] [Keras](https://keras.io/getting_started/): a deep learning API written in Python.<br>\n",
    "[3] [Tensorflow](https://www.tensorflow.org/api_docs/python/tf): an open source machine learning platform.<br>\n",
    "[4] [MNIST handwritten numbers](http://yann.lecun.com/exdb/mnist/).<br>\n",
    "[5] [pix2pix](https://www.tensorflow.org/tutorials/generative/pix2pix): Image-to-image translation with a conditional GAN.<br>\n",
    "[6] VAE example on [Towards data science](https://towardsdatascience.com/variational-autoencoders-as-generative-models-with-keras-e0c79415a7eb).<br>\n",
    "[7] https://github.com/kartikgill/Autoencoders.<br>\n",
    "[8] https://github.com/dhanushkamath/VariationalAutoencoder. <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports:-numpy-and-matplotlib-and-keras\" data-toc-modified-id=\"Imports:-numpy-and-matplotlib-and-keras-0\"><span class=\"toc-item-num\">0&nbsp;&nbsp;</span>Imports: numpy and matplotlib and keras</a></span></li><li><span><a href=\"#Image-recognition-(Introduction-to-Keras)\" data-toc-modified-id=\"Image-recognition-(Introduction-to-Keras)-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Image recognition (Introduction to Keras)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Test-out-things\" data-toc-modified-id=\"Test-out-things-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Test out things</a></span></li></ul></li><li><span><a href=\"#Try-to-recognize-the-NIST-numbers-wit-a-CNN\" data-toc-modified-id=\"Try-to-recognize-the-NIST-numbers-wit-a-CNN-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Try to recognize the NIST numbers wit a CNN</a></span></li><li><span><a href=\"#Image-Denoiser-(almost-unsupervised-learning)\" data-toc-modified-id=\"Image-Denoiser-(almost-unsupervised-learning)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Image Denoiser (almost unsupervised learning)</a></span></li><li><span><a href=\"#Generative-Adversial-Neural-Networks-(pix2pix)\" data-toc-modified-id=\"Generative-Adversial-Neural-Networks-(pix2pix)-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Generative Adversial Neural Networks (pix2pix)</a></span></li><li><span><a href=\"#Autoencoder-for-dimension-reduction\" data-toc-modified-id=\"Autoencoder-for-dimension-reduction-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Autoencoder for dimension reduction</a></span></li><li><span><a href=\"#Autoencoders-(unsupervised-training)\" data-toc-modified-id=\"Autoencoders-(unsupervised-training)-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Autoencoders (unsupervised training)</a></span></li><li><span><a href=\"#Autoencoder-to-anomaly-detect\" data-toc-modified-id=\"Autoencoder-to-anomaly-detect-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Autoencoder to anomaly detect</a></span></li><li><span><a href=\"#Autoencoders-(Functions)\" data-toc-modified-id=\"Autoencoders-(Functions)-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Autoencoders (Functions)</a></span></li><li><span><a href=\"#Example-1:-Reproducing-randomly-placed-circles\" data-toc-modified-id=\"Example-1:-Reproducing-randomly-placed-circles-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Example 1: Reproducing randomly placed circles</a></span></li><li><span><a href=\"#Example-2:-Reproducing-randomly-placed-circles-with-a-true-autoencoder\" data-toc-modified-id=\"Example-2:-Reproducing-randomly-placed-circles-with-a-true-autoencoder-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Example 2: Reproducing randomly placed circles with a true autoencoder</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports: numpy and matplotlib and keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras: Sequential is the neural-network class, Dense is\n",
    "# the standard network layer\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input  # Let's see how to use it\n",
    "from tensorflow.keras.layers import Dense, GaussianDropout  # Fully connected\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, MaxPool2D  # for CNN\n",
    "from tensorflow.keras.layers import UpSampling2D, Flatten, Reshape  # For Autoencoders\n",
    "from tensorflow.keras import optimizers # to choose more advanced optimizers like 'adam'\n",
    "from tensorflow.keras.datasets import mnist  # dataset of handwritten numbers\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.dpi']=300 # highres display\n",
    "\n",
    "# for subplots within subplots:\n",
    "from matplotlib import gridspec\n",
    "\n",
    "# for nice inset colorbars: (approach changed from lecture 1 'Visualization' notebook)\n",
    "from mpl_toolkits.axes_grid1.inset_locator import InsetPosition\n",
    "\n",
    "# for updating display \n",
    "# (very simple animation)\n",
    "from IPython.display import clear_output\n",
    "from time import time, sleep\n",
    "\n",
    "# Set up a random number generator with a fixed seed, so that\n",
    "# running this whole notebook repeatedly should always give\n",
    "# the same result (useful for debugging)\n",
    "rng = np.random.RandomState(23455)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image recognition (Introduction to Keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loader for the MNIST image data was taken from Nielsen's online book,\n",
    "\n",
    "http://neuralnetworksanddeeplearning.com/chap1.html\n",
    "\n",
    "See specifically the following link, for downloading the MNIST image data (we only need the mnist.pkl.gz package inside the 'data' subdirectory; store it inside the present directory of the notebook):\n",
    "https://github.com/mnielsen/neural-networks-and-deep-learning/archive/master.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "mnist_loader\n",
    "~~~~~~~~~~~~\n",
    "\n",
    "taken from Nielsen's online book:\n",
    "http://neuralnetworksanddeeplearning.com/chap1.html\n",
    "\n",
    "\n",
    "A library to load the MNIST image data.  For details of the data\n",
    "structures that are returned, see the doc strings for ``load_data``\n",
    "and ``load_data_wrapper``.  In practice, ``load_data_wrapper`` is the\n",
    "function usually called by our neural network code.\n",
    "\"\"\"\n",
    "\n",
    "def load_images():\n",
    "    (train_val_X, train_val_y), (test_X, test_y) = mnist.load_data()\n",
    "\n",
    "    # to convert values from 0 to 255 into range 0 to 1.\n",
    "    train_val_X = train_val_X.astype('float32') / 255.\n",
    "    test_X = test_X.astype('float32') / 255.\n",
    "    \n",
    "    # adapt this if using `channels_first` image data format\n",
    "    train_val_X = np.reshape(train_val_X, (len(train_val_X), 28, 28, 1)) \n",
    "    test_X = np.reshape(test_X, (len(test_X), 28, 28, 1))\n",
    "    \n",
    "    train_X = train_val_X[:-10000]\n",
    "    val_X = train_val_X[-10000:]\n",
    "\n",
    "    train_y = train_val_y[:-10000]\n",
    "    val_y = train_val_y[-10000:]\n",
    "    \n",
    "    return (train_X, train_y), (val_X, val_y), (test_X, test_y)\n",
    "\n",
    "\n",
    "def flatten(dataset):\n",
    "    new_dataset = np.zeros([dataset.shape[0], dataset.shape[1]*dataset.shape[2]])\n",
    "\n",
    "    for idx, item in enumerate(dataset):\n",
    "        new_dataset[idx, :] = dataset[idx].flatten()\n",
    "    \n",
    "    return new_dataset\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Return the MNIST data as a tuple containing the training data,\n",
    "    the validation data, and the test data.\n",
    "\n",
    "    The ``training_data`` is returned as a tuple with two entries.\n",
    "    The first entry contains the actual training images.  This is a\n",
    "    numpy ndarray with 50,000 entries.  Each entry is, in turn, a\n",
    "    numpy ndarray with 784 values, representing the 28 * 28 = 784\n",
    "    pixels in a single MNIST image.\n",
    "\n",
    "    The second entry in the ``training_data`` tuple is a numpy ndarray\n",
    "    containing 50,000 entries.  Those entries are just the digit\n",
    "    values (0...9) for the corresponding images contained in the first\n",
    "    entry of the tuple.\n",
    "\n",
    "    The ``validation_data`` and ``test_data`` are similar, except\n",
    "    each contains only 10,000 images.\n",
    "\n",
    "    This is a nice data format, but for use in neural networks it's\n",
    "    helpful to modify the format of the ``training_data`` a little.\n",
    "    That's done in the wrapper function ``load_data_wrapper()``, see\n",
    "    below.\n",
    "    \"\"\"\n",
    "    \n",
    "    tr_imgs, vl_imgs, te_imgs = load_images()\n",
    "    \n",
    "    training_data = (flatten(tr_imgs[0]), tr_imgs[1])\n",
    "    validation_data = (flatten(vl_imgs[0]), vl_imgs[1])\n",
    "    test_data = (flatten(te_imgs[0]), te_imgs[1])\n",
    "    \n",
    "    return (training_data, validation_data, test_data)\n",
    "\n",
    "def load_data_wrapper():\n",
    "    \"\"\"Return a tuple containing ``(training_data, validation_data,\n",
    "    test_data)``. Based on ``load_data``, but the format is more\n",
    "    convenient for use in our implementation of neural networks.\n",
    "\n",
    "    In particular, ``training_data`` is a list containing 50,000\n",
    "    2-tuples ``(x, y)``.  ``x`` is a 784-dimensional numpy.ndarray\n",
    "    containing the input image.  ``y`` is a 10-dimensional\n",
    "    numpy.ndarray representing the unit vector corresponding to the\n",
    "    correct digit for ``x``.\n",
    "\n",
    "    ``validation_data`` and ``test_data`` are lists containing 10,000\n",
    "    2-tuples ``(x, y)``.  In each case, ``x`` is a 784-dimensional\n",
    "    numpy.ndarry containing the input image, and ``y`` is the\n",
    "    corresponding classification, i.e., the digit values (integers)\n",
    "    corresponding to ``x``.a\n",
    "\n",
    "    Obviously, this means we're using slightly different formats for\n",
    "    the training data and the validation / test data.  These formats\n",
    "    turn out to be the most convenient for use in our neural network\n",
    "    code.\"\"\"\n",
    "    \n",
    "    global training_inputs, training_results\n",
    "    global validation_inputs, validation_results\n",
    "    global test_inputs, test_results\n",
    "    global num_samples, numpixels, num_test_samples\n",
    "    \n",
    "    tr_d, va_d, te_d = load_data()\n",
    "    \n",
    "    numpixels = tr_d[0].shape[1]\n",
    "    \n",
    "    num_samples=len(tr_d[0])\n",
    "    training_inputs=np.zeros([num_samples,numpixels])\n",
    "    training_results=np.zeros([num_samples,10])    \n",
    "    for j in range(num_samples):\n",
    "        training_inputs[j,:] = np.reshape(tr_d[0][j], (numpixels))\n",
    "        training_results[j,:] = vectorized_result(tr_d[1][j])\n",
    "#    validation_inputs = [reshape(x, (numpixels)) for x in va_d[0]]\n",
    "#    validation_results = [vectorized_result(y) for y in va_d[1]]\n",
    "\n",
    "    num_test_samples=len(te_d[0])\n",
    "    test_inputs=np.zeros([num_test_samples,numpixels])\n",
    "    test_results=np.zeros([num_test_samples,10])    \n",
    "    for j in range(num_test_samples):\n",
    "        test_inputs[j,:] = np.reshape(te_d[0][j], (numpixels))\n",
    "        test_results[j,:] = vectorized_result(te_d[1][j])\n",
    "\n",
    "def vectorized_result(j):\n",
    "    \"\"\"Return a 10-dimensional unit vector with a 1.0 in the jth\n",
    "    position and zeroes elsewhere.  This is used to convert a digit\n",
    "    (0...9) into a corresponding desired output from the neural\n",
    "    network.\"\"\"\n",
    "    e = np.zeros((10))\n",
    "    e[j] = 1.0\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# initialize the network\n",
    "def init_net():\n",
    "    global net, numpixels\n",
    "    net = Sequential()\n",
    "    # note: batch_input_shape is (batchsize,timesteps,data_dim)\n",
    "    net.add(Dense(30, input_shape=(numpixels,), activation='relu'))\n",
    "    net.add(Dense(10, activation='softmax'))\n",
    "    net.compile(loss='categorical_crossentropy', \n",
    "                optimizer=optimizers.SGD(learning_rate=1.0), \n",
    "                metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize the network\n",
    "def init_net_large():\n",
    "    global net, numpixels\n",
    "    net = Sequential()\n",
    "    # note: batch_input_shape is (batchsize,timesteps,data_dim)\n",
    "    net.add(Dense(100, input_shape=(numpixels,), activation='relu'))\n",
    "    net.add(GaussianDropout(0.1))\n",
    "    net.add(Dense(50, activation='relu'))\n",
    "    net.add(Dense(10, activation='softmax'))\n",
    "    net.compile(loss='categorical_crossentropy', \n",
    "                optimizer=optimizers.SGD(learning_rate=1.0), \n",
    "                metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_on(start,stop,dontprint=False, is_cnn=False):\n",
    "    global test_inputs, test_results\n",
    "    global net, predictions_probs, predictions, true_labels\n",
    "    \n",
    "    if is_cnn:\n",
    "        inputs = np.reshape(test_inputs[start:stop,:], [stop-start, 28, 28])\n",
    "    else:\n",
    "        inputs = test_inputs[start:stop,:]\n",
    "        \n",
    "    \n",
    "    predictions_probs=net.predict_on_batch(inputs)\n",
    "    predictions=np.argmax(predictions_probs,axis=1)\n",
    "    if dontprint==False:\n",
    "        print(\"Predictions: \", predictions)\n",
    "    true_labels=np.argmax(test_results[start:stop,:], axis=1)\n",
    "    if dontprint==False:\n",
    "        print(\"True labels: \", true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def display_image(which):\n",
    "    global test_inputs\n",
    "    \n",
    "    plt.imshow(np.reshape(test_inputs[which,:],[28,28]),interpolation='nearest', cmap='binary')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def display_image_array(which):\n",
    "    global test_inputs\n",
    "    \n",
    "    numcolumns=8\n",
    "    BigImage=np.zeros([28*numcolumns,28*numcolumns])\n",
    "    for j in range(len(which)):\n",
    "        x=(j%numcolumns)*28\n",
    "        y=int(j/numcolumns)*28\n",
    "        BigImage[x:x+28,y:y+28]=np.reshape(test_inputs[which[j],:],[28,28])\n",
    "    plt.imshow(BigImage,interpolation='nearest', cmap='binary')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def display_mistakes(maxnum):\n",
    "    global test_inputs, rest_results, num_test_samples\n",
    "    global true_labels, predictions, predictions_probs\n",
    "    \n",
    "    test_on(0,num_test_samples,dontprint=True)\n",
    "    which=np.where(true_labels!=predictions)[0]\n",
    "    for j in which:\n",
    "        if j<maxnum:\n",
    "            display_image(j)\n",
    "            print(\"True \", true_labels[j], \" - Predicted \", predictions[j], \" with prob. \", predictions_probs[j,predictions[j]])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load_data_wrapper() # load all the MNIST images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "psi=training_inputs-np.sum(training_inputs,axis=0)/num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.reshape(psi[4,:],[28,28]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "psi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display_image_array(range(8*8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init_net_large()  # init_net()  # \n",
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batchsize=100\n",
    "batches=int(num_samples/batchsize)-1\n",
    "costs=np.zeros(batches)\n",
    "\n",
    "t0 = time()\n",
    "for j in range(batches):\n",
    "    costs[j]=net.train_on_batch(training_inputs[j*batchsize:(j+1)*batchsize,:], \n",
    "                                training_results[j*batchsize:(j+1)*batchsize,:])[0]\n",
    "t_done = time() - t0\n",
    "\n",
    "print(\"Elapsed time: %.2f s (%.4f s/step)\" % (t_done, t_done/batches))\n",
    "plt.plot(costs,linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_on(0,20)\n",
    "# see which fraction of the test samples is classified incorrectly\n",
    "test_on(0,num_test_samples,dontprint=True)\n",
    "which=np.where(true_labels!=predictions)[0]\n",
    "print(\"Wrong predictions: \", len(which)/num_test_samples*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# use the keras \"fit\" function to go through the whole data set many times ('epochs'), \n",
    "# and even set aside some validation samples\n",
    "epochs = 30\n",
    "t0 = time()\n",
    "history=net.fit(training_inputs,training_results,batch_size=100,\n",
    "                epochs=epochs,validation_split=0.1)\n",
    "t_done = time() - t0\n",
    "\n",
    "print(\"Elapsed time: %.2f s (%.4f s/epoch)\" % (t_done, t_done/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# see which fraction of the test samples is classified incorrectly\n",
    "test_on(0,num_test_samples,dontprint=True)\n",
    "which=np.where(true_labels!=predictions)[0]\n",
    "print(\"Wrong predictions: \", len(which)/num_test_samples*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "plt.plot(history.history['categorical_accuracy'], linewidth=3)\n",
    "plt.plot(history.history['val_categorical_accuracy'], linewidth=3)\n",
    "plt.show()\n",
    "#fig.savefig(\"Handwritten_MNIST_Fig1_Accuracy.pdf\")\n",
    "#fig.savefig(\"Handwritten_MNIST_Fig2_AccuracyAndValidation.pdf\")\n",
    "#fig.savefig(\"Handwritten_MNIST_Fig4_100_50_DropOut_AccuracyAndValidation.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display_mistakes(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to recognize the MNIST numbers wit a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize the network\n",
    "def cnn_simplest_net(M):\n",
    "    net = Sequential()\n",
    "    # note: batch_input_shape is (batchsize,timesteps,data_dim)\n",
    "    net.add(Conv2D(input_shape=(M,M,1), filters=7, kernel_size=[5,5],\n",
    "                   activation='relu', padding='same'))\n",
    "    net.add(AveragePooling2D(pool_size=4))\n",
    "    net.add(Flatten())\n",
    "    net.add(Dense(10, activation='softmax'))\n",
    "    net.compile(loss='categorical_crossentropy', \n",
    "                optimizer=optimizers.SGD(learning_rate=1.0), \n",
    "                metrics=['categorical_accuracy'])\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the network\n",
    "def cnn_net(M):\n",
    "    net = Sequential()\n",
    "    # note: batch_input_shape is (batchsize,timesteps,data_dim)\n",
    "    net.add(Conv2D(input_shape=(M,M,1), filters=8, kernel_size=[5,5],\n",
    "                   activation='relu', padding='same'))\n",
    "    net.add(AveragePooling2D(pool_size=2))\n",
    "    net.add(Conv2D(input_shape=(M,M,1), filters=8, kernel_size=[5,5],\n",
    "                   activation='relu', padding='same'))\n",
    "    net.add(AveragePooling2D(pool_size=2))\n",
    "    net.add(Flatten())\n",
    "    net.add(Dense(10, activation='softmax'))\n",
    "    net.compile(loss='categorical_crossentropy', \n",
    "                optimizer=optimizers.Adam(learning_rate=0.01), \n",
    "                metrics=['categorical_accuracy'])\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cnn_net(int(np.sqrt(numpixels)))  # cnn_simplest_net(int(np.sqrt(numpixels)))  # \n",
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.reshape(training_inputs, [50000, 28, 28])\n",
    "\n",
    "epochs = 3\n",
    "t0 = time()\n",
    "history=net.fit(train_data,training_results,batch_size=100,\n",
    "                epochs=epochs,validation_split=0.1)\n",
    "t_done = time() - t0\n",
    "\n",
    "print(\"Elapsed time: %.2f s (%.4f s/epoch)\" % (t_done, t_done/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "plt.plot(history.history['categorical_accuracy'], linewidth=3)\n",
    "plt.plot(history.history['val_categorical_accuracy'], linewidth=3)\n",
    "plt.show()\n",
    "#fig.savefig(\"Handwritten_MNIST_Fig1_Accuracy.pdf\")\n",
    "#fig.savefig(\"Handwritten_MNIST_Fig2_AccuracyAndValidation.pdf\")\n",
    "#fig.savefig(\"Handwritten_MNIST_Fig4_100_50_DropOut_AccuracyAndValidation.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see which fraction of the test samples is classified incorrectly\n",
    "test_on(0,num_test_samples,dontprint=True, is_cnn=True)\n",
    "which=np.where(true_labels!=predictions)[0]\n",
    "print(\"Wrong predictions: \", len(which)/num_test_samples*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Denoiser (almost unsupervised learning)\n",
    "\n",
    "*Code based on [this Keras example](https://keras.io/examples/vision/autoencoder/)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_imgs, vl_imgs, te_imgs = load_images()\n",
    "\n",
    "train_X = tr_imgs[0]\n",
    "val_X = vl_imgs[0]\n",
    "test_X = te_imgs[0]\n",
    "\n",
    "noise_factor = 0.5\n",
    "#np.random.normal => random means to obtain random samples and normal means normal or gaussian distribution, i.e. random sample from gaussian distribution\n",
    "train_X_noisy = train_X + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=train_X.shape)  \n",
    "val_X_noisy = val_X + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=val_X.shape) \n",
    "test_X_noisy = test_X + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=test_X.shape) \n",
    "\n",
    "# to make values in the range of 0 to 1, if values < 0 then they will be equal to 0 and values > 1 then they will be equal to 1.\n",
    "train_X_noisy = np.clip(train_X_noisy, 0., 1.)   \n",
    "val_X_noisy = np.clip(val_X_noisy, 0., 1.)\n",
    "test_X_noisy = np.clip(test_X_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(5):\n",
    "  plt.subplot(1, 5, i+1)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.grid(False)\n",
    "  plt.imshow(train_X[i].reshape(28, 28), cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(5):\n",
    "  plt.subplot(1, 5, i+1)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.grid(False)\n",
    "  plt.imshow(train_X_noisy[i].reshape(28, 28), cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Input_img = Input(shape=(28, 28, 1))  \n",
    "\n",
    "\n",
    "x1 = Conv2D(4, (3, 3), activation='relu', padding='same')(Input_img)\n",
    "x1 = MaxPool2D( (2, 2), padding='same')(x1)\n",
    "x2 = Conv2D(8, (3, 3), activation='relu', padding='same')(x1)\n",
    "x2 = MaxPool2D( (2, 2), padding='same')(x2)\n",
    "x3 = Conv2D(16, (3, 3), activation='relu', padding='same')(x2)\n",
    "encoded    = MaxPool2D( (2, 2), padding='same')(x3)\n",
    "\n",
    "# decoding architecture\n",
    "x3 = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x3 = UpSampling2D((2, 2))(x3)\n",
    "x2 = Conv2D(8, (3, 3), activation='relu', padding='same')(x3)\n",
    "x2 = UpSampling2D((2, 2))(x2)\n",
    "x1 = Conv2D(4, (3, 3), activation='relu')(x2)\n",
    "x1 = UpSampling2D((2, 2))(x1)\n",
    "decoded   = Conv2D(1, (3, 3), padding='same')(x1)\n",
    "\n",
    "\n",
    "autoencoder = Model(Input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "a_e = autoencoder.fit(train_X_noisy, train_X,\n",
    "                epochs=100,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(test_X_noisy, test_X),\n",
    "                callbacks=[early_stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to predict the reconstructed images for the original images...\n",
    "pred = autoencoder.predict(test_X_noisy)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.xticks([]) # to remove x-axis  the [] empty list indicates this\n",
    "    plt.yticks([]) # to remove y-axis\n",
    "    plt.grid(False) # to remove grid\n",
    "    plt.imshow(test_X[i].reshape(28, 28), cmap='gray') #display the image \n",
    "plt.tight_layout() # to have a proper space in the subplots\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.xticks([]) # to remove x-axis  the [] empty list indicates this\n",
    "    plt.yticks([]) # to remove y-axis\n",
    "    plt.grid(False) # to remove grid\n",
    "    plt.imshow(test_X_noisy[i].reshape(28, 28), cmap='gray') #display the image \n",
    "plt.tight_layout() # to have a proper space in the subplots\n",
    "plt.show()\n",
    "\n",
    "# to visualize reconstructed images(output of autoencoder)\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.xticks([]) # to remove x-axis  the [] empty list indicates this\n",
    "    plt.yticks([]) # to remove y-axis\n",
    "    plt.grid(False) # to remove grid\n",
    "    plt.imshow(pred[i].reshape(28, 28), cmap='gray') #display the image \n",
    "plt.tight_layout() # to have a proper space in the subplots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversial Neural Networks (pix2pix)\n",
    "\n",
    "Go to `003b_pix2pix.ipynb` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder for dimension reduction\n",
    "\n",
    "Code based on [this example on *Towards data science*](https://ekamperi.github.io/machine%20learning/2021/01/21/encoder-decoder-model.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST data set\n",
    "# (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to [0., 1.]\n",
    "# x_train = x_train / 255.\n",
    "# x_test = x_test / 255.\n",
    "\n",
    "tr_imgs, vl_imgs, te_imgs = load_images()\n",
    "\n",
    "x_train = tr_imgs[0]\n",
    "x_val = vl_imgs[0]\n",
    "x_test = te_imgs[0]\n",
    "y_test = te_imgs[1]\n",
    "\n",
    "# Take a look at the dataset\n",
    "n_samples = 10\n",
    "idx = random.sample(range(x_train.shape[0]), n_samples)\n",
    "plt.figure(figsize=(15,4))\n",
    "for i in range(n_samples):\n",
    "    plt.subplot(1, n_samples, i+1)\n",
    "    plt.imshow(x_train[idx[i]].squeeze());\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the dimension of the latent space (encoding space)\n",
    "latent_dim = 2\n",
    "\n",
    "# Images are 28 by 28\n",
    "img_shape = (x_train.shape[1], x_train.shape[2])\n",
    "\n",
    "encoder = Sequential([\n",
    "    Flatten(input_shape=img_shape),\n",
    "    Dense(192, activation='sigmoid'),\n",
    "    Dense(64, activation='sigmoid'),\n",
    "    Dense(32, activation='sigmoid'),\n",
    "    Dense(latent_dim, name='encoder_output')\n",
    "])\n",
    "\n",
    "decoder = Sequential([\n",
    "    Dense(64, activation='sigmoid', input_shape=(latent_dim,)),\n",
    "    Dense(128, activation='sigmoid'),\n",
    "    Dense(img_shape[0] * img_shape[1], activation='relu'),\n",
    "    Reshape(img_shape)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestEncoder(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, x_test, y_test, ax):\n",
    "        super(TestEncoder, self).__init__()\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.ax = ax\n",
    "        self.current_epoch = 0\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.current_epoch = self.current_epoch + 1\n",
    "        encoder_model = Model(inputs=self.model.input,\n",
    "                              outputs=self.model.get_layer('encoder_output').output)\n",
    "        encoder_output = encoder_model(self.x_test)\n",
    "        plt.subplot(4, 3, self.current_epoch)\n",
    "        plt.scatter(encoder_output[:, 0],\n",
    "                    encoder_output[:, 1], s=20, alpha=0.8,\n",
    "                    cmap='Set1', c=self.y_test[0:x_test.shape[0]])\n",
    "        plt.xlim(-9, 9)\n",
    "        plt.ylim(-9, 9)\n",
    "        plt.xlabel('Latent Dimension 1')\n",
    "        plt.ylabel('Latent Dimension 2')\n",
    "\n",
    "autoencoder = Model(inputs=encoder.input, outputs=decoder(encoder.output))\n",
    "autoencoder.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "model_history = autoencoder.fit(x_train, x_train, epochs=12, batch_size=32, verbose=0,\n",
    "                                callbacks=[TestEncoder(x_test[0:500], y_test[0:500])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model_history.history[\"loss\"])\n",
    "plt.title(\"Loss vs. Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 40\n",
    "fake_sample = np.random.uniform(low=-20, high=20, size=(n_samples, 2))\n",
    "plt.figure(figsize=(15,5))\n",
    "for i in range(n_samples):\n",
    "    plt.subplot(4, n_samples//4, i+1)\n",
    "    fake_encoding = np.array([fake_sample[i]])\n",
    "    fake_digit = decoder(fake_encoding).numpy().squeeze() \n",
    "    plt.imshow(fake_digit);\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Nplot = 21\n",
    "plt.figure(figsize=(15,15))\n",
    "idx = 0\n",
    "for ix in np.linspace(-9, 9, Nplot):\n",
    "    for iy in np.linspace(-9, 9, Nplot):\n",
    "        idx += 1\n",
    "        plt.subplot(Nplot, Nplot, idx)\n",
    "        fake_encoding = np.expand_dims(np.array([ix, iy]), 0)\n",
    "        fake_digit = decoder(fake_encoding).numpy().squeeze() \n",
    "        plt.imshow(fake_digit);\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoders (unsupervised training)\n",
    "\n",
    "Go to https://github.com/kartikgill/Autoencoders/blob/main/Variational%20Autoencoder.ipynb\n",
    "\n",
    "Go to `003c_random_face_generator.ipynb` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Autoencoder to anomaly detect\n",
    "\n",
    "https://keras.io/examples/timeseries/timeseries_anomaly_detection/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": "0",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Table of Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}