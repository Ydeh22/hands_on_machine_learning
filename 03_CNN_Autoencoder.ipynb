{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"><sub>This notebook is distributed under the <a href=\"https://creativecommons.org/licenses/by-sa/4.0/\" target=\"_blank\">Attribution-ShareAlike 4.0 International (CC BY-SA 4.0) license</a>.</sub></div>\n",
    "<h1>Hands on Machine Learning  <span style=\"font-size:12px;\"><i>by <a href=\"https://webgrec.ub.edu/webpages/000004/cat/dmaluenda.ub.edu.html\" target=\"_blank\">David Maluenda</a></i></span></h1>\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://atenea.upc.edu/course/view.php?id=71605\" target=\"_blank\">\n",
    "      <img src=\"https://github.com/dmaluenda/hands_on_machine_learning/raw/master/resources/upc_logo_49px.png\" width=\"130\"/>\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "  </td>\n",
    "  <td>   <!-- gColab -->\n",
    "    <a href=\"https://colab.research.google.com/github/dmaluenda/hands_on_machine_learning/blob/master/03_CNN_Autoencoder.ipynb\" target=\"_blank\">\n",
    "      <img src=\"https://raw.githubusercontent.com/dmaluenda/hands_on_machine_learning/master/resources/colab_logo_32px.png\" />\n",
    "      Run in Google Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>   <!-- github -->\n",
    "    <a href=\"https://github.com/dmaluenda/hands_on_machine_learning/blob/master/03_CNN_Autoencoder.ipynb\" target=\"_blank\">\n",
    "      <img src=\"https://raw.githubusercontent.com/dmaluenda/hands_on_machine_learning/master/resources/github_logo_32px.png\" />\n",
    "      View source on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>   <!-- download -->\n",
    "    <a href=\"https://raw.githubusercontent.com/dmaluenda/hands_on_machine_learning/master/03_CNN_Autoencoder.ipynb\"  target=\"_blank\"\n",
    "          download=\"03_CNN_Autoencoder\">\n",
    "      <img src=\"https://raw.githubusercontent.com/dmaluenda/hands_on_machine_learning/master/resources/download_logo_32px.png\" />\n",
    "      Download notebook\n",
    "      </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\text{III}$. Convolutional Neural Networks and Autoencoders (using Keras)\n",
    "\n",
    "Hands on \"Machine Learning on Classical and Quantum data\" course of\n",
    "[Master in Photonics - PHOTONICS BCN](https://photonics.masters.upc.edu/en/general-information)\n",
    "[[UPC](https://photonics.masters.upc.edu/en) +\n",
    "[UB](https://www.ub.edu/web/ub/en/estudis/oferta_formativa/master_universitari/fitxa/P/M0D0H/index.html?) +\n",
    "[UAB](https://www.uab.cat/en/uab-official-masters-degrees-study-guides/) +\n",
    "[ICFO](https://www.icfo.eu/lang/studies/master-studies)].\n",
    "\n",
    "Tutorial 3\n",
    "\n",
    "This notebook shows how to:\n",
    "- implement a neural network using the Keras module\n",
    "- recognize images with dense nets (supervised learning)\n",
    "- recognize images with convolutional nets (supervised learning)\n",
    "- implement image denoising using pseudo-encoders (almost unsupervised learning)\n",
    "- generate images: U-net, GAN, cGAN and VAE (unsupervised learning)\n",
    "- anomaly detection with a 1D Autoencoder (unsupervised learning)\n",
    "\n",
    "**References**:\n",
    "\n",
    "[1] [Machine Learning for Physicists](https://machine-learning-for-physicists.org/) by Florian Marquardt.<br>\n",
    "[2] [Keras](https://keras.io/getting_started/): a deep learning API written in Python.<br>\n",
    "[3] [Tensorflow](https://www.tensorflow.org/api_docs/python/tf): an open source machine learning platform.<br>\n",
    "[4] [MNIST handwritten numbers](http://yann.lecun.com/exdb/mnist/).<br>\n",
    "[5] [pix2pix](https://www.tensorflow.org/tutorials/generative/pix2pix): Image-to-image translation with a conditional GAN.<br>\n",
    "[6] VAE example on [Towards data science](https://towardsdatascience.com/variational-autoencoders-as-generative-models-with-keras-e0c79415a7eb).<br>\n",
    "[7] https://github.com/kartikgill/Autoencoders.<br>\n",
    "[8] https://github.com/dhanushkamath/VariationalAutoencoder. <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports:-Basically-numpy,-matplotlib-and-tensorflow\" data-toc-modified-id=\"Imports:-Basically-numpy,-matplotlib-and-tensorflow-0\"><span class=\"toc-item-num\">0&nbsp;&nbsp;</span>Imports: Basically numpy, matplotlib and tensorflow</a></span></li><li><span><a href=\"#Import-data\" data-toc-modified-id=\"Import-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import data</a></span></li><li><span><a href=\"#Image-recognition-with-a-perceptron-NN-(Introduction-to-Keras)\" data-toc-modified-id=\"Image-recognition-with-a-perceptron-NN-(Introduction-to-Keras)-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Image recognition with a perceptron NN (Introduction to Keras)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Test-out-things\" data-toc-modified-id=\"Test-out-things-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Test out things</a></span></li></ul></li><li><span><a href=\"#Image-recognition-with-a-CNN\" data-toc-modified-id=\"Image-recognition-with-a-CNN-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Image recognition with a CNN</a></span></li><li><span><a href=\"#Image-Denoiser-(almost-unsupervised-learning)\" data-toc-modified-id=\"Image-Denoiser-(almost-unsupervised-learning)-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Image Denoiser (almost unsupervised learning)</a></span></li><li><span><a href=\"#Generative-Adversarial-Neural-Networks-(pix2pix)\" data-toc-modified-id=\"Generative-Adversarial-Neural-Networks-(pix2pix)-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Generative Adversarial Neural Networks (pix2pix)</a></span></li><li><span><a href=\"#Autoencoder-for-dimension-reduction\" data-toc-modified-id=\"Autoencoder-for-dimension-reduction-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Autoencoder for dimension reduction</a></span></li><li><span><a href=\"#Autoencoders-(unsupervised-training)\" data-toc-modified-id=\"Autoencoders-(unsupervised-training)-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Autoencoders (unsupervised training)</a></span></li><li><span><a href=\"#Timeseries-anomaly-detection-using-an-Autoencoder\" data-toc-modified-id=\"Timeseries-anomaly-detection-using-an-Autoencoder-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Timeseries anomaly detection using an Autoencoder</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-the-data\" data-toc-modified-id=\"Load-the-data-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Load the data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Timeseries-data-without-anomalies\" data-toc-modified-id=\"Timeseries-data-without-anomalies-8.1.1\"><span class=\"toc-item-num\">8.1.1&nbsp;&nbsp;</span>Timeseries data without anomalies</a></span></li><li><span><a href=\"#Timeseries-data-with-anomalies\" data-toc-modified-id=\"Timeseries-data-with-anomalies-8.1.2\"><span class=\"toc-item-num\">8.1.2&nbsp;&nbsp;</span>Timeseries data with anomalies</a></span></li></ul></li><li><span><a href=\"#Prepare-training-data\" data-toc-modified-id=\"Prepare-training-data-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>Prepare training data</a></span></li><li><span><a href=\"#Build-a-model\" data-toc-modified-id=\"Build-a-model-8.3\"><span class=\"toc-item-num\">8.3&nbsp;&nbsp;</span>Build a model</a></span></li><li><span><a href=\"#Train-the-model\" data-toc-modified-id=\"Train-the-model-8.4\"><span class=\"toc-item-num\">8.4&nbsp;&nbsp;</span>Train the model</a></span></li><li><span><a href=\"#Detecting-anomalies\" data-toc-modified-id=\"Detecting-anomalies-8.5\"><span class=\"toc-item-num\">8.5&nbsp;&nbsp;</span>Detecting anomalies</a></span><ul class=\"toc-item\"><li><span><a href=\"#Compare-recontruction\" data-toc-modified-id=\"Compare-recontruction-8.5.1\"><span class=\"toc-item-num\">8.5.1&nbsp;&nbsp;</span>Compare recontruction</a></span></li><li><span><a href=\"#Prepare-test-data\" data-toc-modified-id=\"Prepare-test-data-8.5.2\"><span class=\"toc-item-num\">8.5.2&nbsp;&nbsp;</span>Prepare test data</a></span></li></ul></li><li><span><a href=\"#Plot-anomalies\" data-toc-modified-id=\"Plot-anomalies-8.6\"><span class=\"toc-item-num\">8.6&nbsp;&nbsp;</span>Plot anomalies</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports: Basically numpy, matplotlib and tensorflow\n",
    "`!pip install tensorflow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Sequential # Sequential is the neural-network class\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input  # Let's see how to use it\n",
    "from tensorflow.keras.layers import Dense, GaussianDropout  # Fully connected\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, MaxPool2D  # for CNN\n",
    "from tensorflow.keras.layers import UpSampling2D, Flatten, Reshape  # For Autoencoders\n",
    "from tensorflow.keras import optimizers # to choose more advanced optimizers like 'adam'\n",
    "from tensorflow.keras.datasets import mnist  # dataset of handwritten numbers\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.dpi']=300 # highres display\n",
    "\n",
    "# for subplots within subplots:\n",
    "from matplotlib import gridspec\n",
    "\n",
    "# for nice inset colorbars: (approach changed from lecture 1 'Visualization' notebook)\n",
    "from mpl_toolkits.axes_grid1.inset_locator import InsetPosition\n",
    "\n",
    "# for updating display \n",
    "# (very simple animation)\n",
    "from IPython.display import clear_output\n",
    "from time import time, sleep\n",
    "\n",
    "# Set up a random number generator with a fixed seed, so that\n",
    "# running this whole notebook repeatedly should always give\n",
    "# the same result (useful for debugging)\n",
    "rng = np.random.RandomState(23455)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data\n",
    "\n",
    "The loader for the MNIST image data was taken from Nielsen's online book,\n",
    "\n",
    "http://neuralnetworksanddeeplearning.com/chap1.html\n",
    "\n",
    "See specifically the following link, for downloading the MNIST image data (we only need the mnist.pkl.gz package inside the 'data' subdirectory; store it inside the present directory of the notebook):\n",
    "https://github.com/mnielsen/neural-networks-and-deep-learning/archive/master.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "mnist_loader\n",
    "~~~~~~~~~~~~\n",
    "\n",
    "taken from Nielsen's online book:\n",
    "http://neuralnetworksanddeeplearning.com/chap1.html\n",
    "\n",
    "\n",
    "A library to load the MNIST image data.  For details of the data\n",
    "structures that are returned, see the doc strings for ``load_data``\n",
    "and ``load_data_wrapper``.  In practice, ``load_data_wrapper`` is the\n",
    "function usually called by our neural network code.\n",
    "\"\"\"\n",
    "\n",
    "def load_images():\n",
    "    (train_val_X, train_val_y), (test_X, test_y) = mnist.load_data()\n",
    "\n",
    "    # to convert values from 0 to 255 into range 0 to 1.\n",
    "    train_val_X = train_val_X.astype('float32') / 255.\n",
    "    test_X = test_X.astype('float32') / 255.\n",
    "    \n",
    "    # adapt this if using `channels_first` image data format\n",
    "    train_val_X = np.reshape(train_val_X, (len(train_val_X), 28, 28, 1)) \n",
    "    test_X = np.reshape(test_X, (len(test_X), 28, 28, 1))\n",
    "    \n",
    "    train_X = train_val_X[:-10000]\n",
    "    val_X = train_val_X[-10000:]\n",
    "\n",
    "    train_y = train_val_y[:-10000]\n",
    "    val_y = train_val_y[-10000:]\n",
    "    \n",
    "    return (train_X, train_y), (val_X, val_y), (test_X, test_y)\n",
    "\n",
    "\n",
    "def flatten(dataset):\n",
    "    new_dataset = np.zeros([dataset.shape[0], dataset.shape[1]*dataset.shape[2]])\n",
    "\n",
    "    for idx, item in enumerate(dataset):\n",
    "        new_dataset[idx, :] = dataset[idx].flatten()\n",
    "    \n",
    "    return new_dataset\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Return the MNIST data as a tuple containing the training data,\n",
    "    the validation data, and the test data.\n",
    "\n",
    "    The ``training_data`` is returned as a tuple with two entries.\n",
    "    The first entry contains the actual training images.  This is a\n",
    "    numpy ndarray with 50,000 entries.  Each entry is, in turn, a\n",
    "    numpy ndarray with 784 values, representing the 28 * 28 = 784\n",
    "    pixels in a single MNIST image.\n",
    "\n",
    "    The second entry in the ``training_data`` tuple is a numpy ndarray\n",
    "    containing 50,000 entries.  Those entries are just the digit\n",
    "    values (0...9) for the corresponding images contained in the first\n",
    "    entry of the tuple.\n",
    "\n",
    "    The ``validation_data`` and ``test_data`` are similar, except\n",
    "    each contains only 10,000 images.\n",
    "\n",
    "    This is a nice data format, but for use in neural networks it's\n",
    "    helpful to modify the format of the ``training_data`` a little.\n",
    "    That's done in the wrapper function ``load_data_wrapper()``, see\n",
    "    below.\n",
    "    \"\"\"\n",
    "    \n",
    "    tr_imgs, vl_imgs, te_imgs = load_images()\n",
    "    \n",
    "    training_data = (flatten(tr_imgs[0]), tr_imgs[1])\n",
    "    validation_data = (flatten(vl_imgs[0]), vl_imgs[1])\n",
    "    test_data = (flatten(te_imgs[0]), te_imgs[1])\n",
    "    \n",
    "    return (training_data, validation_data, test_data)\n",
    "\n",
    "def load_data_wrapper():\n",
    "    \"\"\"Return a tuple containing ``(training_data, validation_data,\n",
    "    test_data)``. Based on ``load_data``, but the format is more\n",
    "    convenient for use in our implementation of neural networks.\n",
    "\n",
    "    In particular, ``training_data`` is a list containing 50,000\n",
    "    2-tuples ``(x, y)``.  ``x`` is a 784-dimensional numpy.ndarray\n",
    "    containing the input image.  ``y`` is a 10-dimensional\n",
    "    numpy.ndarray representing the unit vector corresponding to the\n",
    "    correct digit for ``x``.\n",
    "\n",
    "    ``validation_data`` and ``test_data`` are lists containing 10,000\n",
    "    2-tuples ``(x, y)``.  In each case, ``x`` is a 784-dimensional\n",
    "    numpy.ndarry containing the input image, and ``y`` is the\n",
    "    corresponding classification, i.e., the digit values (integers)\n",
    "    corresponding to ``x``.a\n",
    "\n",
    "    Obviously, this means we're using slightly different formats for\n",
    "    the training data and the validation / test data.  These formats\n",
    "    turn out to be the most convenient for use in our neural network\n",
    "    code.\"\"\"\n",
    "    \n",
    "    global training_inputs, training_results\n",
    "    global validation_inputs, validation_results\n",
    "    global test_inputs, test_results\n",
    "    global num_samples, numpixels, num_test_samples\n",
    "    \n",
    "    tr_d, va_d, te_d = load_data()\n",
    "    \n",
    "    numpixels = tr_d[0].shape[1]\n",
    "    \n",
    "    num_samples=len(tr_d[0])\n",
    "    training_inputs=np.zeros([num_samples,numpixels])\n",
    "    training_results=np.zeros([num_samples,10])    \n",
    "    for j in range(num_samples):\n",
    "        training_inputs[j,:] = np.reshape(tr_d[0][j], (numpixels))\n",
    "        training_results[j,:] = vectorized_result(tr_d[1][j])\n",
    "#    validation_inputs = [reshape(x, (numpixels)) for x in va_d[0]]\n",
    "#    validation_results = [vectorized_result(y) for y in va_d[1]]\n",
    "\n",
    "    num_test_samples=len(te_d[0])\n",
    "    test_inputs=np.zeros([num_test_samples,numpixels])\n",
    "    test_results=np.zeros([num_test_samples,10])    \n",
    "    for j in range(num_test_samples):\n",
    "        test_inputs[j,:] = np.reshape(te_d[0][j], (numpixels))\n",
    "        test_results[j,:] = vectorized_result(te_d[1][j])\n",
    "\n",
    "def vectorized_result(j):\n",
    "    \"\"\"Return a 10-dimensional unit vector with a 1.0 in the jth\n",
    "    position and zeroes elsewhere.  This is used to convert a digit\n",
    "    (0...9) into a corresponding desired output from the neural\n",
    "    network.\"\"\"\n",
    "    e = np.zeros((10))\n",
    "    e[j] = 1.0\n",
    "    return e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image recognition with a perceptron NN (Introduction to Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# initialize the network\n",
    "def init_net():\n",
    "    global net, numpixels\n",
    "    net = Sequential()\n",
    "    # note: batch_input_shape is (batchsize,timesteps,data_dim)\n",
    "    net.add(Dense(30, input_shape=(numpixels,), activation='relu'))\n",
    "    net.add(Dense(10, activation='softmax'))\n",
    "    net.compile(loss='categorical_crossentropy', \n",
    "                optimizer=optimizers.SGD(learning_rate=1.0), \n",
    "                metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize the network\n",
    "def init_net_large():\n",
    "    global net, numpixels\n",
    "    net = Sequential()\n",
    "    # note: batch_input_shape is (batchsize,timesteps,data_dim)\n",
    "    net.add(Dense(100, input_shape=(numpixels,), activation='relu'))\n",
    "    net.add(GaussianDropout(0.1))\n",
    "    net.add(Dense(50, activation='relu'))\n",
    "    net.add(Dense(10, activation='softmax'))\n",
    "    net.compile(loss='categorical_crossentropy', \n",
    "                optimizer=optimizers.SGD(learning_rate=1.0), \n",
    "                metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_on(start,stop,dontprint=False, is_cnn=False):\n",
    "    global test_inputs, test_results\n",
    "    global net, predictions_probs, predictions, true_labels\n",
    "    \n",
    "    if is_cnn:\n",
    "        inputs = np.reshape(test_inputs[start:stop,:], [stop-start, 28, 28])\n",
    "    else:\n",
    "        inputs = test_inputs[start:stop,:]\n",
    "        \n",
    "    \n",
    "    predictions_probs=net.predict_on_batch(inputs)\n",
    "    predictions=np.argmax(predictions_probs,axis=1)\n",
    "    if dontprint==False:\n",
    "        print(\"Predictions: \", predictions)\n",
    "    true_labels=np.argmax(test_results[start:stop,:], axis=1)\n",
    "    if dontprint==False:\n",
    "        print(\"True labels: \", true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def display_image(which):\n",
    "    global test_inputs\n",
    "    \n",
    "    plt.imshow(np.reshape(test_inputs[which,:],[28,28]),interpolation='nearest', cmap='binary')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def display_image_array(which):\n",
    "    global test_inputs\n",
    "    \n",
    "    numcolumns=8\n",
    "    BigImage=np.zeros([28*numcolumns,28*numcolumns])\n",
    "    for j in range(len(which)):\n",
    "        x=(j%numcolumns)*28\n",
    "        y=int(j/numcolumns)*28\n",
    "        BigImage[x:x+28,y:y+28]=np.reshape(test_inputs[which[j],:],[28,28])\n",
    "    plt.imshow(BigImage,interpolation='nearest', cmap='binary')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def display_mistakes(maxnum):\n",
    "    global test_inputs, rest_results, num_test_samples\n",
    "    global true_labels, predictions, predictions_probs\n",
    "    \n",
    "    test_on(0,num_test_samples,dontprint=True)\n",
    "    which=np.where(true_labels!=predictions)[0]\n",
    "    for j in which:\n",
    "        if j<maxnum:\n",
    "            display_image(j)\n",
    "            print(\"True \", true_labels[j], \" - Predicted \", predictions[j], \" with prob. \", predictions_probs[j,predictions[j]])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load_data_wrapper() # load all the MNIST images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "psi=training_inputs-np.sum(training_inputs,axis=0)/num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.reshape(psi[4,:],[28,28]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "psi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display_image_array(range(8*8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init_net()  # init_net_large()  # \n",
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batchsize=100\n",
    "batches=int(num_samples/batchsize)-1\n",
    "costs=np.zeros(batches)\n",
    "\n",
    "t0 = time()\n",
    "for j in range(batches):\n",
    "    costs[j]=net.train_on_batch(training_inputs[j*batchsize:(j+1)*batchsize,:], \n",
    "                                training_results[j*batchsize:(j+1)*batchsize,:])[0]\n",
    "t_done = time() - t0\n",
    "\n",
    "print(\"Elapsed time: %.2f s (%.4f s/step)\" % (t_done, t_done/batches))\n",
    "plt.plot(costs,linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_on(0,20)\n",
    "# see which fraction of the test samples is classified incorrectly\n",
    "test_on(0,num_test_samples,dontprint=True)\n",
    "which=np.where(true_labels!=predictions)[0]\n",
    "print(\"Wrong predictions: \", len(which)/num_test_samples*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# use the keras \"fit\" function to go through the whole data set many times ('epochs'), \n",
    "# and even set aside some validation samples\n",
    "epochs = 30\n",
    "t0 = time()\n",
    "history=net.fit(training_inputs,training_results,batch_size=100,\n",
    "                epochs=epochs,validation_split=0.1)\n",
    "t_done = time() - t0\n",
    "\n",
    "print(\"Elapsed time: %.2f s (%.4f s/epoch)\" % (t_done, t_done/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# see which fraction of the test samples is classified incorrectly\n",
    "test_on(0,num_test_samples,dontprint=True)\n",
    "which=np.where(true_labels!=predictions)[0]\n",
    "print(\"Wrong predictions: \", len(which)/num_test_samples*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "plt.plot(history.history['categorical_accuracy'], linewidth=3)\n",
    "plt.plot(history.history['val_categorical_accuracy'], linewidth=3)\n",
    "plt.show()\n",
    "#fig.savefig(\"Handwritten_MNIST_Fig1_Accuracy.pdf\")\n",
    "#fig.savefig(\"Handwritten_MNIST_Fig2_AccuracyAndValidation.pdf\")\n",
    "#fig.savefig(\"Handwritten_MNIST_Fig4_100_50_DropOut_AccuracyAndValidation.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display_mistakes(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image recognition with a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize the network\n",
    "def cnn_simplest_net(M):\n",
    "    net = Sequential()\n",
    "    # note: batch_input_shape is (batchsize,timesteps,data_dim)\n",
    "    net.add(Conv2D(input_shape=(M,M,1), filters=7, kernel_size=[5,5],\n",
    "                   activation='relu', padding='same'))\n",
    "    net.add(AveragePooling2D(pool_size=4))\n",
    "    net.add(Flatten())\n",
    "    net.add(Dense(10, activation='softmax'))\n",
    "    net.compile(loss='categorical_crossentropy', \n",
    "                optimizer=optimizers.SGD(learning_rate=1.0), \n",
    "                metrics=['categorical_accuracy'])\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the network\n",
    "def cnn_net(M):\n",
    "    net = Sequential()\n",
    "    # note: batch_input_shape is (batchsize,timesteps,data_dim)\n",
    "    net.add(Conv2D(input_shape=(M,M,1), filters=8, kernel_size=[5,5],\n",
    "                   activation='relu', padding='same'))\n",
    "    net.add(AveragePooling2D(pool_size=2))\n",
    "    net.add(Conv2D(input_shape=(M,M,1), filters=8, kernel_size=[5,5],\n",
    "                   activation='relu', padding='same'))\n",
    "    net.add(AveragePooling2D(pool_size=2))\n",
    "    net.add(Flatten())\n",
    "    net.add(Dense(10, activation='softmax'))\n",
    "    net.compile(loss='categorical_crossentropy', \n",
    "                optimizer=optimizers.Adam(learning_rate=0.01), \n",
    "                metrics=['categorical_accuracy'])\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cnn_net(int(np.sqrt(numpixels)))  # cnn_simplest_net(int(np.sqrt(numpixels)))  # \n",
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.reshape(training_inputs, [50000, 28, 28])\n",
    "\n",
    "epochs = 3\n",
    "t0 = time()\n",
    "history=net.fit(train_data,training_results,batch_size=100,\n",
    "                epochs=epochs,validation_split=0.1)\n",
    "t_done = time() - t0\n",
    "\n",
    "print(\"Elapsed time: %.2f s (%.4f s/epoch)\" % (t_done, t_done/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "plt.plot(history.history['categorical_accuracy'], linewidth=3)\n",
    "plt.plot(history.history['val_categorical_accuracy'], linewidth=3)\n",
    "plt.show()\n",
    "#fig.savefig(\"Handwritten_MNIST_Fig1_Accuracy.pdf\")\n",
    "#fig.savefig(\"Handwritten_MNIST_Fig2_AccuracyAndValidation.pdf\")\n",
    "#fig.savefig(\"Handwritten_MNIST_Fig4_100_50_DropOut_AccuracyAndValidation.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see which fraction of the test samples is classified incorrectly\n",
    "test_on(0,num_test_samples,dontprint=True, is_cnn=True)\n",
    "which=np.where(true_labels!=predictions)[0]\n",
    "print(\"Wrong predictions: \", len(which)/num_test_samples*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Denoiser (almost unsupervised learning)\n",
    "\n",
    "*Code based on [this Keras example](https://keras.io/examples/vision/autoencoder/)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_imgs, vl_imgs, te_imgs = load_images()\n",
    "\n",
    "train_X = tr_imgs[0]\n",
    "val_X = vl_imgs[0]\n",
    "test_X = te_imgs[0]\n",
    "\n",
    "noise_factor = 0.5\n",
    "#np.random.normal => random means to obtain random samples and normal means normal or gaussian distribution, i.e. random sample from gaussian distribution\n",
    "train_X_noisy = train_X + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=train_X.shape)  \n",
    "val_X_noisy = val_X + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=val_X.shape) \n",
    "test_X_noisy = test_X + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=test_X.shape) \n",
    "\n",
    "# to make values in the range of 0 to 1, if values < 0 then they will be equal to 0 and values > 1 then they will be equal to 1.\n",
    "train_X_noisy = np.clip(train_X_noisy, 0., 1.)   \n",
    "val_X_noisy = np.clip(val_X_noisy, 0., 1.)\n",
    "test_X_noisy = np.clip(test_X_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(5):\n",
    "  plt.subplot(1, 5, i+1)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.grid(False)\n",
    "  plt.imshow(train_X[i].reshape(28, 28), cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(5):\n",
    "  plt.subplot(1, 5, i+1)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.grid(False)\n",
    "  plt.imshow(train_X_noisy[i].reshape(28, 28), cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Input_img = Input(shape=(28, 28, 1))  \n",
    "\n",
    "\n",
    "x1 = Conv2D(4, (3, 3), activation='relu', padding='same')(Input_img)\n",
    "x1 = MaxPool2D( (2, 2), padding='same')(x1)\n",
    "x2 = Conv2D(8, (3, 3), activation='relu', padding='same')(x1)\n",
    "x2 = MaxPool2D( (2, 2), padding='same')(x2)\n",
    "x3 = Conv2D(16, (3, 3), activation='relu', padding='same')(x2)\n",
    "encoded    = MaxPool2D( (2, 2), padding='same')(x3)\n",
    "\n",
    "# decoding architecture\n",
    "x3 = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x3 = UpSampling2D((2, 2))(x3)\n",
    "x2 = Conv2D(8, (3, 3), activation='relu', padding='same')(x3)\n",
    "x2 = UpSampling2D((2, 2))(x2)\n",
    "x1 = Conv2D(4, (3, 3), activation='relu')(x2)\n",
    "x1 = UpSampling2D((2, 2))(x1)\n",
    "decoded   = Conv2D(1, (3, 3), padding='same')(x1)\n",
    "\n",
    "\n",
    "autoencoder = Model(Input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "a_e = autoencoder.fit(train_X_noisy, train_X,\n",
    "                epochs=100,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(test_X_noisy, test_X),\n",
    "                callbacks=[early_stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to predict the reconstructed images for the original images...\n",
    "pred = autoencoder.predict(test_X_noisy)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.xticks([]) # to remove x-axis  the [] empty list indicates this\n",
    "    plt.yticks([]) # to remove y-axis\n",
    "    plt.grid(False) # to remove grid\n",
    "    plt.imshow(test_X[i].reshape(28, 28), cmap='gray') #display the image \n",
    "plt.tight_layout() # to have a proper space in the subplots\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.xticks([]) # to remove x-axis  the [] empty list indicates this\n",
    "    plt.yticks([]) # to remove y-axis\n",
    "    plt.grid(False) # to remove grid\n",
    "    plt.imshow(test_X_noisy[i].reshape(28, 28), cmap='gray') #display the image \n",
    "plt.tight_layout() # to have a proper space in the subplots\n",
    "plt.show()\n",
    "\n",
    "# to visualize reconstructed images(output of autoencoder)\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.xticks([]) # to remove x-axis  the [] empty list indicates this\n",
    "    plt.yticks([]) # to remove y-axis\n",
    "    plt.grid(False) # to remove grid\n",
    "    plt.imshow(pred[i].reshape(28, 28), cmap='gray') #display the image \n",
    "plt.tight_layout() # to have a proper space in the subplots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversarial Neural Networks (pix2pix)\n",
    "\n",
    "Go to `003b_pix2pix.ipynb` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder for dimension reduction\n",
    "\n",
    "Code based on [this example on *Towards data science*](https://ekamperi.github.io/machine%20learning/2021/01/21/encoder-decoder-model.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST data set\n",
    "# (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to [0., 1.]\n",
    "# x_train = x_train / 255.\n",
    "# x_test = x_test / 255.\n",
    "\n",
    "tr_imgs, vl_imgs, te_imgs = load_images()\n",
    "\n",
    "x_train = tr_imgs[0]\n",
    "x_val = vl_imgs[0]\n",
    "x_test = te_imgs[0]\n",
    "y_test = te_imgs[1]\n",
    "\n",
    "# Take a look at the dataset\n",
    "n_samples = 10\n",
    "idx = random.sample(range(x_train.shape[0]), n_samples)\n",
    "plt.figure(figsize=(15,4))\n",
    "for i in range(n_samples):\n",
    "    plt.subplot(1, n_samples, i+1)\n",
    "    plt.imshow(x_train[idx[i]].squeeze());\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the dimension of the latent space (encoding space)\n",
    "latent_dim = 2\n",
    "\n",
    "# Images are 28 by 28\n",
    "img_shape = (x_train.shape[1], x_train.shape[2])\n",
    "\n",
    "encoder = Sequential([\n",
    "    Flatten(input_shape=img_shape),\n",
    "    Dense(192, activation='sigmoid'),\n",
    "    Dense(64, activation='sigmoid'),\n",
    "    Dense(32, activation='sigmoid'),\n",
    "    Dense(latent_dim, name='encoder_output')\n",
    "])\n",
    "\n",
    "decoder = Sequential([\n",
    "    Dense(64, activation='sigmoid', input_shape=(latent_dim,)),\n",
    "    Dense(128, activation='sigmoid'),\n",
    "    Dense(img_shape[0] * img_shape[1], activation='relu'),\n",
    "    Reshape(img_shape)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestEncoder(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, x_test, y_test, ax):\n",
    "        super(TestEncoder, self).__init__()\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.ax = ax\n",
    "        self.current_epoch = 0\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.current_epoch = self.current_epoch + 1\n",
    "        encoder_model = Model(inputs=self.model.input,\n",
    "                              outputs=self.model.get_layer('encoder_output').output)\n",
    "        encoder_output = encoder_model(self.x_test)\n",
    "        plt.subplot(4, 3, self.current_epoch)\n",
    "        plt.scatter(encoder_output[:, 0],\n",
    "                    encoder_output[:, 1], s=20, alpha=0.8,\n",
    "                    cmap='Set1', c=self.y_test[0:x_test.shape[0]])\n",
    "        plt.xlim(-9, 9)\n",
    "        plt.ylim(-9, 9)\n",
    "        plt.xlabel('Latent Dimension 1')\n",
    "        plt.ylabel('Latent Dimension 2')\n",
    "\n",
    "autoencoder = Model(inputs=encoder.input, outputs=decoder(encoder.output))\n",
    "autoencoder.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "model_history = autoencoder.fit(x_train, x_train, epochs=12, batch_size=32, verbose=0,\n",
    "                                callbacks=[TestEncoder(x_test[0:500], y_test[0:500])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model_history.history[\"loss\"])\n",
    "plt.title(\"Loss vs. Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 40\n",
    "fake_sample = np.random.uniform(low=-20, high=20, size=(n_samples, 2))\n",
    "plt.figure(figsize=(15,5))\n",
    "for i in range(n_samples):\n",
    "    plt.subplot(4, n_samples//4, i+1)\n",
    "    fake_encoding = np.array([fake_sample[i]])\n",
    "    fake_digit = decoder(fake_encoding).numpy().squeeze() \n",
    "    plt.imshow(fake_digit);\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Nplot = 21\n",
    "plt.figure(figsize=(15,15))\n",
    "idx = 0\n",
    "for ix in np.linspace(-9, 9, Nplot):\n",
    "    for iy in np.linspace(-9, 9, Nplot):\n",
    "        idx += 1\n",
    "        plt.subplot(Nplot, Nplot, idx)\n",
    "        fake_encoding = np.expand_dims(np.array([ix, iy]), 0)\n",
    "        fake_digit = decoder(fake_encoding).numpy().squeeze() \n",
    "        plt.imshow(fake_digit);\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoders (unsupervised training)\n",
    "\n",
    "Go to https://github.com/kartikgill/Autoencoders/blob/main/Variational%20Autoencoder.ipynb\n",
    "\n",
    "Go to `003c_random_face_generator.ipynb` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Timeseries anomaly detection using an Autoencoder\n",
    "\n",
    "https://keras.io/examples/timeseries/timeseries_anomaly_detection/\n",
    "\n",
    "**Author:** [pavithrasv](https://github.com/pavithrasv)<br>\n",
    "**Date created:** 2020/05/31<br>\n",
    "**Last modified:** 2020/05/31<br>\n",
    "\n",
    "This script demonstrates how you can use a reconstruction convolutional autoencoder model to detect anomalies in timeseries data.\n",
    "\n",
    "### Load the data\n",
    "\n",
    "We will use the [Numenta Anomaly Benchmark(NAB)](\n",
    "https://www.kaggle.com/boltzmannbrain/nab) dataset. It provides artifical\n",
    "timeseries data containing labeled anomalous periods of behavior. Data are\n",
    "ordered, timestamped, single-valued metrics.\n",
    "\n",
    "We will use the `art_daily_small_noise.csv` file for training and the\n",
    "`art_daily_jumpsup.csv` file for testing. The simplicity of this dataset\n",
    "allows us to demonstrate anomaly detection effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_url_root = \"https://raw.githubusercontent.com/numenta/NAB/master/data/\"\n",
    "\n",
    "df_small_noise_url_suffix = \"artificialNoAnomaly/art_daily_small_noise.csv\"\n",
    "df_small_noise_url = master_url_root + df_small_noise_url_suffix\n",
    "df_small_noise = pd.read_csv(\n",
    "    df_small_noise_url, parse_dates=True, index_col=\"timestamp\"\n",
    ")\n",
    "\n",
    "df_daily_jumpsup_url_suffix = \"artificialWithAnomaly/art_daily_jumpsup.csv\"\n",
    "df_daily_jumpsup_url = master_url_root + df_daily_jumpsup_url_suffix\n",
    "df_daily_jumpsup = pd.read_csv(\n",
    "    df_daily_jumpsup_url, parse_dates=True, index_col=\"timestamp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_small_noise.head())\n",
    "print(df_daily_jumpsup.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the data\n",
    "\n",
    "#### Timeseries data without anomalies\n",
    "\n",
    "We will use the following data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "df_small_noise.plot(legend=False, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timeseries data with anomalies\n",
    "\n",
    "We will use the following data for testing and see if the sudden jump up in the\n",
    "data is detected as an anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "df_daily_jumpsup.plot(legend=False, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training data\n",
    "\n",
    "Get data values from the training timeseries data file and normalize the\n",
    "`value` data. We have a `value` for every 5 mins for 14 days.\n",
    "\n",
    "-   24 * 60 / 5 = **288 timesteps per day**\n",
    "-   288 * 14 = **4032 data points** in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and save the mean and std we get,\n",
    "# for normalizing test data.\n",
    "training_mean = df_small_noise.mean()\n",
    "training_std = df_small_noise.std()\n",
    "df_training_value = (df_small_noise - training_mean) / training_std\n",
    "print(\"Number of training samples:\", len(df_training_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create sequences combining `TIME_STEPS` contiguous data values from the\n",
    "training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEPS = 288\n",
    "\n",
    "# Generated training sequences for use in the model.\n",
    "def create_sequences(values, time_steps=TIME_STEPS):\n",
    "    output = []\n",
    "    for i in range(len(values) - time_steps + 1):\n",
    "        output.append(values[i : (i + time_steps)])\n",
    "    return np.stack(output)\n",
    "\n",
    "\n",
    "x_train = create_sequences(df_training_value.values)\n",
    "print(\"Training input shape: \", x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model\n",
    "\n",
    "We will build a convolutional reconstruction autoencoder model. The model will\n",
    "take input of shape `(batch_size, sequence_length, num_features)` and return\n",
    "output of the same shape. In this case, `sequence_length` is 288 and\n",
    "`num_features` is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = tf.keras.layers\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(x_train.shape[1], x_train.shape[2])),\n",
    "        layers.Conv1D(\n",
    "            filters=32, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "        ),\n",
    "        layers.Dropout(rate=0.2),\n",
    "        layers.Conv1D(\n",
    "            filters=16, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "        ),\n",
    "        layers.Conv1DTranspose(\n",
    "            filters=16, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "        ),\n",
    "        layers.Dropout(rate=0.2),\n",
    "        layers.Conv1DTranspose(\n",
    "            filters=32, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "        ),\n",
    "        layers.Conv1DTranspose(filters=1, kernel_size=7, padding=\"same\"),\n",
    "    ]\n",
    ")\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "Please note that we are using `x_train` as both the input and the target\n",
    "since this is a reconstruction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train,\n",
    "    x_train,\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\")\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot training and validation loss to see how the training went."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting anomalies\n",
    "\n",
    "We will detect anomalies by determining how well our model can reconstruct\n",
    "the input data.\n",
    "\n",
    "\n",
    "1.   Find MAE loss on training samples.\n",
    "2.   Find max MAE loss value. This is the worst our model has performed trying\n",
    "to reconstruct a sample. We will make this the `threshold` for anomaly\n",
    "detection.\n",
    "3.   If the reconstruction loss for a sample is greater than this `threshold`\n",
    "value then we can infer that the model is seeing a pattern that it isn't\n",
    "familiar with. We will label this sample as an `anomaly`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train MAE loss.\n",
    "x_train_pred = model.predict(x_train)\n",
    "train_mae_loss = np.mean(np.abs(x_train_pred - x_train), axis=1)\n",
    "\n",
    "plt.hist(train_mae_loss, bins=50)\n",
    "plt.xlabel(\"Train MAE loss\")\n",
    "plt.ylabel(\"No of samples\")\n",
    "plt.show()\n",
    "\n",
    "# Get reconstruction loss threshold.\n",
    "threshold = np.max(train_mae_loss)\n",
    "print(\"Reconstruction error threshold: \", threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare recontruction\n",
    "\n",
    "Just for fun, let's see how our model has recontructed the first sample.\n",
    "This is the 288 timesteps from day 1 of our training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking how the first sequence is learnt\n",
    "plt.plot(x_train[0])\n",
    "plt.plot(x_train_pred[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df_test_value = (df_daily_jumpsup - training_mean) / training_std\n",
    "fig, ax = plt.subplots()\n",
    "df_test_value.plot(legend=False, ax=ax)\n",
    "plt.show()\n",
    "\n",
    "# Create sequences from test values.\n",
    "x_test = create_sequences(df_test_value.values)\n",
    "print(\"Test input shape: \", x_test.shape)\n",
    "\n",
    "# Get test MAE loss.\n",
    "x_test_pred = model.predict(x_test)\n",
    "test_mae_loss = np.mean(np.abs(x_test_pred - x_test), axis=1)\n",
    "test_mae_loss = test_mae_loss.reshape((-1))\n",
    "\n",
    "plt.hist(test_mae_loss, bins=50)\n",
    "plt.xlabel(\"test MAE loss\")\n",
    "plt.ylabel(\"No of samples\")\n",
    "plt.show()\n",
    "\n",
    "# Detect all the samples which are anomalies.\n",
    "anomalies = test_mae_loss > threshold\n",
    "print(\"Number of anomaly samples: \", np.sum(anomalies))\n",
    "print(\"Indices of anomaly samples: \", np.where(anomalies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot anomalies\n",
    "\n",
    "We now know the samples of the data which are anomalies. With this, we will\n",
    "find the corresponding `timestamps` from the original test data. We will be\n",
    "using the following method to do that:\n",
    "\n",
    "Let's say time_steps = 3 and we have 10 training values. Our `x_train` will\n",
    "look like this:\n",
    "\n",
    "- 0, 1, 2\n",
    "- 1, 2, 3\n",
    "- 2, 3, 4\n",
    "- 3, 4, 5\n",
    "- 4, 5, 6\n",
    "- 5, 6, 7\n",
    "- 6, 7, 8\n",
    "- 7, 8, 9\n",
    "\n",
    "All except the initial and the final time_steps-1 data values, will appear in\n",
    "`time_steps` number of samples. So, if we know that the samples\n",
    "[(3, 4, 5), (4, 5, 6), (5, 6, 7)] are anomalies, we can say that the data point\n",
    "5 is an anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data i is an anomaly if samples [(i - timesteps + 1) to (i)] are anomalies\n",
    "anomalous_data_indices = []\n",
    "for data_idx in range(TIME_STEPS - 1, len(df_test_value) - TIME_STEPS + 1):\n",
    "    if np.all(anomalies[data_idx - TIME_STEPS + 1 : data_idx]):\n",
    "        anomalous_data_indices.append(data_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's overlay the anomalies on the original test data plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df_daily_jumpsup.iloc[anomalous_data_indices]\n",
    "fig, ax = plt.subplots()\n",
    "df_daily_jumpsup.plot(legend=False, ax=ax)\n",
    "df_subset.plot(legend=False, ax=ax, color=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": "0",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Table of Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}